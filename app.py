import streamlit as st
import pandas as pd
from docx import Document
import io
from difflib import SequenceMatcher
import re

# ---------------------------------------------------------------------------
# Helper: highlight differences between two strings
# ---------------------------------------------------------------------------

def get_highlighted_diff(text1: str, text2: str) -> str:
    """Return *text1* with segments that do **not** occur in *text2* highlighted
    yellow using inline HTML.  We compare *text1* against *text2* so we can show
    the missing / altered parts visually to the user.
    """
    matcher = SequenceMatcher(None, text2, text1, autojunk=False)
    pieces: list[str] = []
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        fragment = text1[j1:j2]
        if tag == "equal":
            pieces.append(fragment)
        else:  # "replace", "insert" â†’ highlight what is *only* in text1
            pieces.append(
                f"<span style=\"background-color:#fdd835;\">{fragment}</span>"
            )
    return "".join(pieces)


# ---------------------------------------------------------------------------
# DOCX parsing
# ---------------------------------------------------------------------------

def parse_docx(file_content: bytes):
    """Read a .docx file and build two maps:

    * *doc_data* maps a **full key** like ``L65:T3`` to the cleaned paragraph
      text (only for **nonâ€‘empty** paragraphs).
    * *line_to_key_map* maps a **line number only** (65) to the key that exists
      *for that exact line* â€“ including empty paragraphs.  This preserves the
      original Word line numbering so that Excel references stay aligned.
    """
    doc_data: dict[str, str] = {}
    line_to_key_map: dict[int, str] = {}

    doc = Document(io.BytesIO(file_content))

    for line_no, para in enumerate(doc.paragraphs, start=1):
        tab_count = para.text.count("\t")
        key = f"L{line_no}:T{tab_count}"
        line_to_key_map[line_no] = key
        clean_text = para.text.strip()
        if clean_text:
            doc_data[key] = clean_text

    return doc_data, line_to_key_map


# ---------------------------------------------------------------------------
# Location parsing (Excel â†’ real keys)
# ---------------------------------------------------------------------------

def parse_location_string(
    location_str: str,
    line_to_key_map: dict[int, str],
    doc_data: dict[str, str],
):
    """Translate a location string from Excel into a list of keys.

    *Single* location â€“ we respect the exact ``T`` value when present, so
    ``L65:T3`` matches **only** that precise paragraph.  If the user gives
    ``L65:C`` (sometimes they note checkâ€‘columns) we fall back to the default
    paragraph for that line (whatever *Word* actually has).

    *Range* â€“ we keep the previous behaviour: use only the line numbers so
    "L21:T0 - L24:T3" means *lines* 21â€“24, regardless of their actual tab
    indentation.
    """
    location_str = location_str.strip()

    # ------------------------------------------------------------------
    # Range handling
    # ------------------------------------------------------------------
    if " - " in location_str:
        try:
            start_loc, end_loc = (p.strip() for p in location_str.split(" - ", 1))
            line_re = r"L(\d+):(?:T\d+|C)"
            start_m, end_m = re.match(line_re, start_loc), re.match(line_re, end_loc)
            if not (start_m and end_m):
                return []
            start_ln, end_ln = int(start_m.group(1)), int(end_m.group(1))
            return [
                line_to_key_map.get(ln)
                for ln in range(start_ln, end_ln + 1)
                if line_to_key_map.get(ln)
            ]
        except Exception:
            return []

    # ------------------------------------------------------------------
    # Single location
    # ------------------------------------------------------------------
    single_re = r"L(?P<line>\d+):(?:(?:T(?P<tab>\d+))|C)"
    m = re.match(single_re, location_str)
    if not m:
        return []

    line_num = int(m.group("line"))
    tab_val = m.group("tab")

    if tab_val is not None:  # Explicit Tâ€¦ given â€“ require exact match
        key = f"L{line_num}:T{int(tab_val)}"
        return [key] if key in doc_data else []

    # "C" shorthand â€“ use whatever tab count the doc actually has
    key = line_to_key_map.get(line_num)
    return [key] if key else []


# ---------------------------------------------------------------------------
# Main checker
# ---------------------------------------------------------------------------

def run_checker(df: pd.DataFrame, doc_data: dict, line_to_key_map: dict[int, str]):
    """Validate each Excel row and build a list of result dictionaries."""
    results: list[dict] = []

    if len(df.columns) < 6:
        st.error("Error: The Excel file must have at least 6 columns.")
        return None

    sentence_col = df.columns[3]  # 4th column
    location_col = df.columns[5]  # 6th column

    for idx, row in df.iterrows():
        sentence = str(row.get(sentence_col, "")).strip()
        location_raw = str(row.get(location_col, "")).strip()
        if not sentence or not location_raw or sentence.lower() == "nan" or location_raw.lower() == "nan":
            continue  # skip blank lines

        result = {
            "excel_row": idx + 2,  # +2 (header row + zeroâ€‘based index)
            "location": location_raw,
            "sentence": sentence,
            "status": "",
            "details": "",
        }

        loc_keys = parse_location_string(location_raw, line_to_key_map, doc_data)
        if not loc_keys:
            result["status"] = "âŒ Error"
            result["details"] = (
                f"The location `{location_raw}` could not be resolved. "
                "Check the format (e.g. `L21:T0`, `L24:C`, or `L21:T0 - L24:T3`)."
            )
            results.append(result)
            continue

        doc_texts = [doc_data[key] for key in loc_keys if key in doc_data]

        # ------------------------------------------------------------------
        # Exact match?
        # ------------------------------------------------------------------
        if any(sentence in para for para in doc_texts):
            result["status"] = "âœ… Correct"
            result["details"] = "The sentence was found exactly at the specified location."  # noqa: E501
        else:
            combined = " ".join(doc_texts)
            result["status"] = "âŒ Incorrect"
            result["details"] = (
                "The sentence was **not** found at the targeted location. "
                "Differences versus the text in that block are highlighted below:"
            )
            result["highlighted"] = get_highlighted_diff(sentence, combined)
            result["doc_text"] = combined

        results.append(result)

    return results


# ---------------------------------------------------------------------------
# Streamlit UI
# ---------------------------------------------------------------------------

st.set_page_config(layout="wide")
st.title("ðŸ“„ Extractive Sentence Checker Tool")

st.info(
    """
    **How to use this tool:**

    1. Upload the meeting minutes as a `.docx` file (à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸²à¸£à¸›à¸£à¸°à¸Šà¸¸à¸¡).
    2. Upload the corresponding Excel file with sentences to verify.  The Excel
       file must include a header row.
    3. The app will check whether each sentence appears **exactly** at the
       location you specified.
    """
)

col1, col2 = st.columns(2)
with col1:
    st.subheader("1. Upload DOCX File (à¸šà¸±à¸™à¸—à¸¶à¸à¸à¸²à¸£à¸›à¸£à¸°à¸Šà¸¸à¸¡)")
    docx_file = st.file_uploader("Upload your .docx file", type=["docx"], key="docx")
with col2:
    st.subheader("2. Upload Excel File")
    xlsx_file = st.file_uploader("Upload your .xlsx file", type=["xlsx"], key="xlsx")

if docx_file and xlsx_file:
    st.markdown("---")
    st.header("Results")

    try:
        doc_data, line_to_key_map = parse_docx(docx_file.getvalue())
        df = pd.read_excel(xlsx_file, header=0)
        results = run_checker(df, doc_data, line_to_key_map)

        if results:
            for res in results:
                with st.expander(
                    f"**Row {res['excel_row']} | Location: {res['location']} | Status: {res['status']}**"
                ):
                    st.markdown("**Sentence to Check:**")
                    st.markdown(f"> {res['sentence']}")
                    st.markdown("**Details:** " + res["details"])

                    if res.get("highlighted"):
                        st.markdown("**Highlighted Differences:**")
                        st.markdown(res["highlighted"], unsafe_allow_html=True)
                        st.markdown("**Original Text from Document:**")
                        st.markdown(f"> {res['doc_text']}")

    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
        st.error("Please verify that the uploaded files are valid and the Excel file contains a header row.")
